1. Install Python3 and pip
Install Python3 and then check to make sure the python version is 3+

% brew install python
% python --version
python 3.8.3
Install pip

% curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
% python get-pip.py
To install Airflow, make sure the pip version is 20.2.4

% pip install --upgrade pip==20.2.4
% pip --version
pip 20.2.4 from /usr/local/anaconda3/lib/python3.8/site-packages/pip (python 3.8)
2. [Optional] Create a Virtual Environment Install Airflow
Generally, installing a virtual environment is good practice so you don’t cluster your native environment with a lot of packages. A virtual environment can be easily activated and deactivated. Install virtualenv and create a name for the virtual environment, the name in this case will be venv.

% pip install virtualenv
% virtualenv -p python venv
Now activate the virtual environment so that all packages get install onto the virtual environment rather than your computer.

% source venv/bin/activate
Now your virtual environment is activated. Your console should now have (venv) before it.

3. Install and Setup Airflow
Install Airflow in a new airflow directory

(venv) % mkdir airflow && cd airflow
(venv) % pip install apache-airflow
Setup the proper directory structure and create a new airflow folder. First get the path to the airflow folder with pwd and then export that as the airflow home directory to that path.

(venv) % pwd
/Users/<username>/airflow/airflow
(venv) % export AIRFLOW_HOME=/Users/<userid>/airflow/airflow
Lastly, initialize the Airflow database. Airflow uses a Sqlite database to keep track of metadata for all of the airflow DAGs.

(venv) % airflow db init
Now you should see a bunch of files inside the airflow directory. In the following terminal output, I use a package called tree but ls also works. tree is a really useful package to view the structure of a directory.

(venv) % brew install tree
(venv) f.liang@fliang-ltm airflow % tree
.
├── airflow.cfg
├── airflow.db
├── logs
│   └── scheduler
│     ├── 2021-04-16
│     └── latest -> /Users/<userid>/airflow/logs/scheduler/2021-04-16
├── unittests.cfg
└── webserver_config.py
4. Startup Airflow
On the first startup of Airflow, you have to create a new user. I have just used simple admin for most of the fields but you can customize it.

(venv) % airflow users create \
      --role Admin \
      --username admin \
      --email admin \
      --firstname admin \
      --lastname admin \
      --password admin
To check if the user was successfully added, list out all users

(venv) % airflow users list
id | username | email | first_name | last_name | roles
===+==========+=======+============+===========+======
1  | admin    | admin | admin      | admin     | Admin
Then startup the Airflow job scheduler

% airflow scheduler
Create a new terminal (CMD + T on Mac)and setup the AIRFLOW_HOME path again. Don’t forget to activate the virtual environment if you previously setup a virtual environment. If you don’t then the airflow commands will not work in the new terminal. Then start the webserver.

(venv) % export AIRFLOW_HOME=/Users/<userid>/airflow/airflow
(venv) % airflow webserver
From here, everything should be setup so open up any web browser and go to localhost:8080. 8080 should be the default port in your airflow.cfg file but if that does not work, open up your airflow.cfg file and look for the web_server_port field and make it 8080. From here, simply enter the username and password you created before (both username and password areadmin) and login.


Once you login, there are a lot of sample airflow jobs that you can look through and run.


5. Creating your own DAGs
To stop the example DAGs from showing up, open your airflow.cfg file and set load_examples to False and then create a dag folder as specified in the dags_folder variable in airflow.cfg. The fault dags folder path is AIRFLOW_HOME/dags.

(venv) % mkdir /Users/<userid>/airflow/airflow/dags
Add your DAG files into the dags/ folder and the Airflow scheduler will automatically pick up the dags and reflect it in the webserver within minutes. Any compilation errors will also show up in the UI and also in the logs folder.

---Reference : https://towardsdatascience.com/an-introduction-to-apache-airflow-21111bf98c1f